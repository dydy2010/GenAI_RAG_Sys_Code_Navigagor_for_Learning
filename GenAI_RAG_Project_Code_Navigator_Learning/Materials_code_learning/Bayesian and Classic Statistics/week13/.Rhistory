data = read.csv("students.csv")
head(data)
female_height = data[data["gender"]== "Female","height"][0:50]
head(female_height)
dens = density(female_height)
plot(dens)
par(mfrow=c(1,1))
qqnorm(female_height)
qqline(female_height)
modelString = "
data {
int n;
real y[n];
}
parameters {
real<lower=0,upper=500> mu;
real<lower=10,upper=10.1> sigma;
}
model {
for (i in 1:n)
y[i] ~ normal(mu,sigma);
}
" # close quote for modelString
model <- stan_model(model_code=modelString)
library(rstan)
modelString = "
data {
int n;
real y[n];
}
parameters {
real<lower=0,upper=500> mu;
real<lower=10,upper=10.1> sigma;
}
model {
for (i in 1:n)
y[i] ~ normal(mu,sigma);
}
" # close quote for modelString
model <- stan_model(model_code=modelString)
n     = length(female_height)
y     = female_height
stanFit = sampling( object=model , data=list( y = y , n = n ))
params_f = rstan::extract(stanFit)
plot_posterior(params_f, Rope=c(.05,.2))
library(bayestestR)
library(latex2exp)
par(mfrow=c(1,2))
plot_posterior(params_f, Rope=c(.05,.2))
modelString = "
data {
int n;
real y[n];
}
parameters {
real<lower=0,upper=500> mu;
real<lower=10,upper=10.1> sigma;
}
model {
for (i in 1:n)
y[i] ~ normal(mu,sigma);
}
" # close quote for modelString
model <- stan_model(model_code=modelString)
n     = length(female_height)
y     = female_height
stanFit = sampling( object=model , data=list( y = y , n = n ))
params_f = rstan::extract(stanFit)
plot_posterior(params_f, Rope=c(.05,.2))
plot_posterior <- function(params, Rope = c(.4,.5)){
dens <- density(params$mu)
max_dens <- max(dens$y)
hdi_l <- as.numeric(hdi(params$mu)[2])
hdi_r <- as.numeric(hdi(params$mu)[3])
plot(dens,main="Posterior",col="darkseagreen", TeX("$\\mu$"))
lines(c(hdi_l,hdi_r),c(.12*max_dens,.12*max_dens),col="orange")
text(hdi_l,.15*max_dens,round(hdi_l,3),cex=.6)
text(hdi_r,.15*max_dens,round(hdi_r,3),cex=.6)
text((hdi_l+hdi_r)/2,.15*max_dens,"95% HDI",cex=.6,col="orange")
lines(c(Rope[1],Rope[2]),c(.08*max_dens,.08*max_dens),col="blue")
text(Rope[1],.05*max_dens,Rope[1],cex=.6)
text(Rope[2],.05*max_dens,Rope[2],cex=.6)
text((Rope[1]+Rope[2])/2,.05*max_dens,"ROPE",cex=.6, col="blue")
}
library(rstan)
library(bayestestR)
library(latex2exp)
rstan_options(auto_write = TRUE)
data = read.csv("husband_wife.csv")
head(data)
View(data)
diff = data[,"age.husband"] - data[,"age.wife"]
head(diff)
dens = density(diff)
plot(dens)
par(mfrow=c(1,1))
qqnorm(diff)
qqline(diff)
female_height = data[data["gender"]== "Female","height"][0:50]
modelString = "
data {
int n;
real y[n];
}
parameters {
real<lower=-10,upper=10> mu;
real<lower=4,upper=4.1> sigma;
}
model {
for (i in 1:n)
y[i] ~ normal(mu,sigma);
}
" # close quote for modelString
model <- stan_model(model_code=modelString)
n     = length(diff)
y     = diff
stanFit = sampling( object=model , data=list( y = y , n = n ))
params = rstan::extract(stanFit)
plot_posterior(params, Rope=c(-2,2))
stanFit = sampling( object=model , data=list( y = y , n = n ))
params = rstan::extract(stanFit)
plot_posterior(params, Rope=c(-2,2))
# exercises week 13 last class
library(rstan)
library(bayestestR)
library(latex2exp)
rstan_options(auto_write = TRUE)
plot_posterior <- function(params, Rope = c(-100,.-99)){
dens <- density(params$mu)
max_dens <- max(dens$y)
hdi_l <- as.numeric(hdi(params$mu)[2])
hdi_r <- as.numeric(hdi(params$mu)[3])
plot(dens, main="Posterior", col="darkseagreen", TeX("$\\mu$"), lwd=2)
lines(c(hdi_l,hdi_r), c(.12*max_dens,.12*max_dens), col="orange", lwd=2)
text(hdi_l, .15*max_dens, round(hdi_l,3), cex=
text(hdi_r, .15*max_dens, round(hdi_r,3), cex=
.8)
.8)
library(rstan)
library(bayestestR)
library(latex2exp)
rstan_options(auto_write = TRUE)
plot_posterior <- function(params, Rope = c(-100,.-99)){
dens <- density(params$mu)
max_dens <- max(dens$y)
hdi_l <- as.numeric(hdi(params$mu)[2])
hdi_r <- as.numeric(hdi(params$mu)[3])
plot(dens, main="Posterior", col="darkseagreen", TeX("$\\mu$"), lwd=2)
lines(c(hdi_l,hdi_r), c(.12*max_dens,.12*max_dens), col="orange", lwd=2)
text(hdi_l, .15*max_dens, round(hdi_l,3), cex=
text(hdi_r, .15*max_dens, round(hdi_r,3), cex=
.8)
.8)
# exercises week 13 last class
library(rstan)
library(bayestestR)
library(latex2exp)
rstan_options(auto_write = TRUE)
plot_posterior <- function(params, Rope = c(-100,.-99)){
dens <- density(params$mu)
max_dens <- max(dens$y)
hdi_l <- as.numeric(hdi(params$mu)[2])
hdi_r <- as.numeric(hdi(params$mu)[3])
plot(dens, main="Posterior", col="darkseagreen", TeX("$\\mu$"), lwd=2)
lines(c(hdi_l,hdi_r), c(.12*max_dens,.12*max_dens), col="orange", lwd=2)
text(hdi_l, .15*max_dens, round(hdi_l,3), cex=
text(hdi_r, .15*max_dens, round(hdi_r,3), cex=.8)
text((hdi_l+hdi_r)/2, .15*max_dens, "95% HDI", cex=.8, col="orange")
rstan_options(auto_write = TRUE)
plot_posterior <- function(params, Rope = c(-100,.-99)){
dens <- density(params$mu)
max_dens <- max(dens$y)
hdi_l <- as.numeric(hdi(params$mu)[2])
hdi_r <- as.numeric(hdi(params$mu)[3])
plot(dens, main="Posterior", col="darkseagreen", TeX("$\\mu$"), lwd=2)
lines(c(hdi_l,hdi_r), c(.12*max_dens,.12*max_dens), col="orange", lwd=2)
text(hdi_l, .15*max_dens, round(hdi_l,3), cex=.8)
text(hdi_r, .15*max_dens, round(hdi_r,3), cex=.8)
text((hdi_l+hdi_r)/2, .15*max_dens, "95% HDI", cex=.8, col="orange")
lines(c(Rope[1],Rope[2]), c(.08*max_dens, .08*max_dens), col="blue", lwd=2)
text(Rope[1], .05*max_dens,Rope[1], cex=.8)
text(Rope[2], .05*max_dens,Rope[2], cex=.8)
text((Rope[1]+Rope[2])/2, .05*max_dens, "ROPE", cex=.8, col="blue")
}
wine<-c(71, 69, 67, 68, 73, 72, 71, 71, 68, 72, 69, 72)
mean<-mean(wine)
sd<-sd(wine)
quantile(wine,prob=0.05)
quantile(wine,prob=0.05)
qnorm(p=0.05,mean_wine,sd_wine)
mean_wine<-mean(wine)
sd_wine<-sd(wine)
quantile(wine,prob=0.05)
qnorm(p=0.05,mean_wine,sd_wine)
quantile(wine,prob=0.05)
qnorm(p=0.05,mean_wine,sd_wine)
qqnorm(wine)
qqline(wine)
# c) Determine the 95 %-HDI and the mode of the data.
density_wine <- density(wine)
mode_estimate <- density_wine$x[which.max(density_wine$y)]
data {
data {int<lower=0> N;vector[N] y;}
install.packages("HDInterval")  # If not already installed
library(HDInterval)
hdi_95 <- hdi(mu_samples, credMass = 0.95)
install.packages("HDInterval")  # If not already installed
library(HDInterval)
hdi_95 <- hdi(mu, credMass = 0.95)
install.packages("HDInterval")
library(HDInterval)
hdi_95 <- hdi(mu, credMass = 0.95)
hdi_95 <- hdi(mean_wine, credMass = 0.95)
print(hdi_95)
data {int<lower=0> N;vector[N] y;}
data {
plot(density_wine)
mode_estimate
#next part is totally gpt
# 1. Define the model as a string
modelString <- "
data {
int<lower=0> N;
vector[N] y;
}
parameters {
real mu;
real<lower=0> sigma;
}
model {
mu    ~ uniform(65, 75);
sigma ~ normal(0, 5);
y     ~ normal(mu, sigma);
}
"
# 2. Compile the model
library(rstan)
model <- stan_model(model_code = modelString)
# 3. Prepare data and run MCMC
wine <- c(71, 69, 67, 68, 73, 72, 71, 71, 68, 72, 69, 72)
N <- length(wine)
stanFit <- sampling(
object = model,
data   = list(N = N, y = wine),
chains = 3,
iter   = 2000,
warmup = 500,
refresh = 0
)
# 4. Extract posterior samples
params <- rstan::extract(stanFit)
mu_samps <- params$mu
# 5. Compute the 95% HDI
library(HDInterval)
hdi_mu <- hdi(mu_samps, credMass = 0.95)  # returns c(lower, upper)
hdi_95 <- hdi(mean_wine, credMass = 0.95)
print(hdi_95)
hdi_mu <- hdi(mu_samps, credMass = 0.95)  # returns c(lower, upper)
post_mat <- as.matrix(stanFit)
# 2. Extract draws of mu
mu_samps <- post_mat[ , "mu" ]
wine<-c(71, 69, 67, 68, 73, 72, 71, 71, 68, 72, 69, 72)
mean_wine<-mean(wine)
sd_wine<-1.5
quantile(wine,prob=0.05)
qnorm(p=0.05,mean_wine,sd_wine)
# The empirical quantile from the data.
# The theoretical quantile assuming a normal distribution with the same mean and standard deviation.
qqnorm(wine)
qqline(wine)
density_wine <- density(wine)
mode_estimate <- density_wine$x[which.max(density_wine$y)]
plot(density_wine)
mode_estimate
#next part is totally gpt
# Problem 13.1 Full Bayesian Solution with rstan
# ---------------------------------------------
library(rstan)
library(HDInterval)
# Data from problem statement
wine <- c(71, 69, 67, 68, 73, 72, 71, 71, 68, 72, 69, 72)
n <- length(wine)
known_sd <- 1.5  # Ïƒ = 1.5 (known)
# a) Normality Assessment ------------------------------------------------
# Bayesian approach: Posterior predictive check
stan_code_ppc <- "
data {
int<lower=0> N;
real y[N];
real mu_prior_lower;
real mu_prior_upper;
}
parameters {
real mu;
}
model {
mu ~ uniform(mu_prior_lower, mu_prior_upper);
y ~ normal(mu, 1.5);  // Known sigma = 1.5
}
generated quantities {
real y_rep[12];  // Generate replicate data
for (i in 1:12) {
y_rep[i] = normal_rng(mu, 1.5);
}
}
"
# Fit model with conservative uniform prior (60-80)
stan_data <- list(
N = n,
y = wine,
mu_prior_lower = 60,
mu_prior_upper = 80
)
fit_ppc <- stan(
model_code = stan_code_ppc,
data = stan_data,
iter = 4000,
chains = 4
)
# Posterior predictive check
y_rep <- as.matrix(fit_ppc, pars = "y_rep")
ppc_dens_overlay(wine, y_rep[1:50,]) +
ggtitle("Posterior Predictive Check") +
theme_minimal()
