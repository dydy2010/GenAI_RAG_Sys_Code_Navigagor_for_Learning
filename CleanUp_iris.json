{"name": "CleanUp_iris", "extension": ".py", "course": "CIP", "st_mode": 33204, "st_ino": 13098505, "st_dev": 16777233, "st_nlink": 1, "st_uid": 501, "st_gid": 20, "st_size": 7621, "st_atime": 1759510059.5224364, "st_mtime": 1759493740.0, "st_ctime": 1759510056.3070304, "st_birthtime": 1759493740.0, "st_blocks": 16, "st_blksize": 4096, "content": "# Example for Data Cleaning\n# https://github.com/DJCordhose/ml-examples\n\nimport pandas as pd\n\npd.set_option('display.precision', 3)\npd.set_option('display.max_rows', 20)\npd.set_option('display.max_colwidth', 30)\n\n# Get and Load the Data\n\nurl = \"https://raw.githubusercontent.com/DJCordhose/ml-examples/master/datasets/Iris/iris_dirty.csv\"\ncolumns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'class']\ndf = pd.read_csv(url, header = None, names=columns )\n\n# what is the expected output of the following code?\n# some examples: \n# df.iloc[5:10]              \n# df.iloc[5:10,[1,3]]        \n# df.iloc[:,1:5]             \n# df.iloc[:,[1,3,4]]         \n# df.iloc[[2,4,7]]          \n# df.iloc[[2,4,7],[1,3,4]]  \n\n# check your guesses!\n\n###################\n# Get an overview\n###################\n\n# use count to count the entries for each column\ndf.count()\n\n# use sample to take n arbitrary rows\ndf.sample(3)\n\n# use describe() to find a statistical summary on the numerical columns\ndf.describe()\n\n# why are there only 3 columns?\n# use info() to get information about data types and nan values\ndf.info()\n# does that explain the result of df.describe()?\n\n# use value_counts to see how many elements belong to each unique value of the column 'class'\n\ndf[\"class\"].value_counts()\n\n# why is there only 1 entry for Iris-setsoa?\n\n###################\n# Groupby unique values of columns\n###################\n\n# Each unique value gets a columns, the aggregation function 'count' tells you what the values are. (try also other aggregation functions as: mean, max, min, std, etc.)\ndf.groupby('class').count()\n\n\n###################\n# Find NaN values\n###################\n\n# find rows with at least one NaN elemnt\ndf[df.isnull().any(axis=1)]     # explain the result of this line => show below step by step!\n\n# Let's explore this command step by step:\ndf.isnull()\n\ndf.isnull().any(axis=1)         # Question: is 'any' element 'True' in axis=1??  Output as Series !\ndf.isnull().any(axis=0)\n\n# NOTE: you can also use isna() instaed of isnull() -> equivalent\ndf.isna().any(axis=1)\n\n# Now find out where the values are, which are NaN\ndf.loc[df.isna().any(axis=1)]    \n\ndf.iloc[81:84]                 # here we see our NaN value!!!\n\n###################\n# Replace NaN values\n###################\n\ndf_iris_versicolor = df[df['class']  == 'Iris-versicolor']\n\nprint(df_iris_versicolor[\"sepal width\"].mean())\nprint(\"-\"*40)\nprint(df[\"sepal width\"].fillna(999).loc[81:84])\nprint(\"-\"*40)\nprint(df[\"sepal width\"].fillna(2.999 ).loc[81:84])                     # random value 2.999!\n\n# create a new column with NaNs filled by mean value\n\ndf[\"sepal_width2\"] = df[\"sepal width\"].fillna(df_iris_versicolor[\"sepal width\"].mean())\ndf[81:84]\n\ndf.info()             # one more column is visible with one less NaN value\n\n# HINT: use rolling() to replace nan values with means of custom window sizes, e.g. the 5 elements before, instead of the entire column!\n\n###################\n# Remove duplicates\n###################\n\ndf.duplicated()\ndf[df.duplicated()] # shows only lines already existing once\ndf[df.duplicated(keep=False)]    # show all values - not only the duplicated!\n\n# drop_duplicates() is an inplace-Operation => values are dropped for ever! Therefore BE CAREFUL!\n# For testing, it is better to first create a new data frame (e.g. df_dup_free).\n\ndf_dup_free = df.drop_duplicates()          # Records 34,37 and 100 are droped\ndf_dup_free[df_dup_free.duplicated()]       # show all duplicated rows => NOW nothing!!!\ndf_dup_free[28:39]                          # show the deleted rows  34 and 37 \n\n# HINT: keep metainformat as e.g. how many rows will be removed etc.\n\n# Let's drop the duplicate row 100: \nprint(df.index[[100]])\niris_test = df.drop(df.index[[100]])\nprint(iris_test.iloc[98:102])\n\n# now let's do it with our original dataframe:\n\ndf.drop(df.index[100], inplace = True)\ndf[90:105]                       # row 100 is deleted!!!!\n\n###################\n# Handle typos\n###################\n\ndf[\"class\"].value_counts()\n# there is a simple 'Typo' on one value: Iris-setsoa is wrong!\n\ndf.replace({\"class\": {\"Iris-setsoa\": \"Iris-setosa\"}}, inplace=True)\ndf[\"class\"].value_counts()\n\ndf.groupby('class').count()\n\n###################\n# Handle data types\n###################\n\ndf.info()\n# some entry caused \"petal width\" to be read in as object type\ndf.head()\n# now it's clear that the \"mm\" is responsible for that\n\n# we use replace in combination with a type cast to create a new clean petal_width_2 column\ndf[\"petal_width2\"] = df[\"petal width\"].replace(\"mm\", \"\", regex=True).astype(dtype=float,errors=\"ignore\")\n\ndf.loc[66:70]                    # 15 mm != 15 cm  =>  15mm == 1.5 cm\n\n# Be carefule, the other columns seem to be measured in cm! (not mm)\ndf[\"petal_width2\"]= df[\"petal_width2\"]/10          \ndf.loc[66:70]\ndf.info()\n\n# NOTE: The 'stage' phases (xxx_xxx_2) could possibly be skipped\n#                 But ALWAYS be careful so that there is no confusion and you can still \n#                 understand the original values at the end.\n#                 Remove and rename if you want\n\n#                 You can rename the original colmns with a \"_\"-prefix\n# df.rename(columns={\"sepal width\": \"_sepal width\", \n#                    \"petal width\": \"_petal width\",\n#                    \"sepal length\": \"_sepal length\",\n#                    \"petal length\": \"_petal length\",\n#                                                  }, inplace=True)\n\n# df.rename(columns={\"sepal_width2\": \"sepal_width\", \n#                    \"petal_width2\": \"petal_width\"}, inplace=True)\n\n\n###################\n# Outliers\n###################\n\n# We look for outliers!\ndf.describe()\n\n# you find potential outliers already by comparing the stat values from df.describe()\n# For example: the max value of sepal length is 58, with a mean of ~6 and a std of ~4\n\ndf[df[\"sepal length\"] > 10]\ndf[\"sepal_length2\"] = df[\"sepal length\"]\n\n# set the value 58.0 to None in 'sepal_length2'\ndf.loc[df[\"sepal_length2\"] > 10, \"sepal_length2\"] = None     # perhaps 5.8 would be better ... or mean ... or? \n\ndf.describe()                  # show the 'max'-values, count, mean, std. \n\n# Alternatively, we can replace the value with the mean of all entries belonging to the same class\n# show all values with 'Iris-virginica' in column \"sepal_length2\"\ndf[df['class']  == 'Iris-virginica'][\"sepal_length2\"]    \n\n# calculate the mean-value of all 'Iris-virginica'-valus in column \"sepal_length2\"\n\nvsl_mean = df[df['class']  == 'Iris-virginica'][\"sepal_length2\"].mean()\ndf[\"sepal_length2\"] = df[\"sepal_length2\"].fillna(vsl_mean)   # fill all NaN-Values with the vsl_mean\n\ndf[df[\"sepal length\"] > 10]\n\n# again, if you want, rename and keep the column naming consistent\n# df.rename(columns={\"sepal_length2\": \"sepal_length\"}, inplace=True)\n\ndf.describe()\ndf.info()\n\n###################\n# Renaming and reordering and saving\n###################\n\n# At the moment we only have one column untouched. Pragmatically, we will add a new one and split our dataframe into an original and a cleaned one.\n# there are other ways of doing that!\n\ndf['petal_length2'] = df['petal length']\ndf_clean = df[df.columns[4:]]\ndf_clean.columns = list(map(lambda x: x.replace(\"2\",\"\"), df_clean.columns)) # replace all the '2's with empty string in columns names\n# reorder\nreordered_cols = ['sepal_width', 'sepal_length', 'petal_width', 'petal_length', 'class']\ndf_clean = df_clean[reordered_cols]\n\n# quickly check \nprint(\"-------------------------\")\nprint(\"\\nSUMMARY cleaned:\\n\\n\")\nprint(df_clean.describe())\nprint(\"\\n\")\nprint(df_clean.info())\n\n# save to new file if you want\n# df_clean.to_csv(\"iris_clean.csv\", index=False)\n"}